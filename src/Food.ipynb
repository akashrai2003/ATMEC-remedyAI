{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\akash\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "login(\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.schema import Document\n",
    "# Load the CSV file\n",
    "csv_file_path = r'A:\\Downloads\\Remedy.ai\\datasets\\formatted_nutrients.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Assuming the CSV has a single column with combined text, named 'text_column'\n",
    "# Replace 'text_column' with the actual name of the column if different\n",
    "texts = df['Nutrients'].tolist()\n",
    "\n",
    "# Create documents without splitting, keeping each row as one document\n",
    "documents = [Document(page_content=text) for text in texts]\n",
    "\n",
    "# Set up the embeddings for GPU usage\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "model_kwargs = {'device': 'cuda'}  # Use 'cuda' to enable GPU\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Created on GPU.......\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "# Create the vector store in Chroma\n",
    "vector_store = Chroma.from_documents(documents, embeddings, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=r\"A:\\Downloads\\Remedy.ai\\store\\doc_cosine\")\n",
    "\n",
    "print(\"Vector Store Created on GPU.......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_TYPE = os.getenv(\"AZURE_OPENAI_API_TYPE\")\n",
    "AZURE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # Update the environment variable name\n",
    "OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "\n",
    "# Ensure all variables are correctly set\n",
    "if not all([OPENAI_API_KEY, OPENAI_API_TYPE, AZURE_ENDPOINT, OPENAI_API_VERSION]):\n",
    "    raise ValueError(\"Some environment variables are missing.\")\n",
    "\n",
    "# Instantiate the AzureChatOpenAI model using LangChain with the correct parameters\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_ENDPOINT,  # Use azure_endpoint instead of openai_api_base\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_version=OPENAI_API_VERSION,\n",
    "    openai_api_type=OPENAI_API_TYPE,\n",
    "    deployment_name=\"Test\",  # Ensure this is your correct deployment name\n",
    "    temperature=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_19236\\2028116667.py:32: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  context = retriever.get_relevant_documents(query)\n",
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_19236\\2028116667.py:39: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: To create a dietary plan for a patient with diabetes and hypertension, it is crucial to focus on foods that are low in sodium, saturated fat, and sugars, while being rich in nutrients like fiber, vitamins, and minerals. Here are some dietary considerations and relevant foods based on the provided nutritional values:\n",
      "\n",
      "### Dietary Considerations:\n",
      "1. **Low Sodium**: To manage hypertension, it is essential to limit sodium intake.\n",
      "2. **Low Saturated Fat**: To reduce the risk of cardiovascular complications, limit foods high in saturated fats.\n",
      "3. **Low Sugars and Carbohydrates**: To manage blood glucose levels for diabetes, focus on foods low in sugars and carbohydrates.\n",
      "4. **High Fiber**: Fiber helps in controlling blood sugar levels and improving heart health.\n",
      "5. **Rich in Essential Nutrients**: Foods rich in vitamins, minerals, and antioxidants are beneficial.\n",
      "\n",
      "### Relevant Foods:\n",
      "Based on the nutritional values provided for \"Cheese, cheddar or colby, low-sodium,\" let's identify if it fits the dietary considerations:\n",
      "\n",
      "- **Sodium**: 21.00 mg (low)\n",
      "- **Saturated Fat**: 21g (high)\n",
      "- **Sugars**: 0.49 g (low)\n",
      "- **Carbohydrates**: 1.91 g (low)\n",
      "- **Fiber**: 0.0 g (none)\n",
      "- **Protein**: 24.35 g (high, which is beneficial)\n",
      "- **Vitamins and Minerals**: High in calcium (703.00 mg), phosphorus (484.00 mg), and vitamin A (996.00 IU)\n",
      "\n",
      "### Analysis:\n",
      "- **Cheese, cheddar or colby, low-sodium**: While this cheese is low in sodium and sugars, it is high in saturated fat, which might not be ideal for a patient with hypertension. However, it is rich in protein and essential nutrients like calcium and vitamin A.\n",
      "\n",
      "### Alternative Food Suggestions:\n",
      "1. **Vegetables**: Leafy greens (spinach, kale), broccoli, and bell peppers are low in calories, sodium, and carbohydrates but high in fiber and essential nutrients.\n",
      "2. **Fruits**: Berries (strawberries, blueberries), apples, and pears are low in sugars and high in fiber.\n",
      "3. **Whole Grains**: Oats, quinoa, and brown rice are high in fiber and have a low glycemic index.\n",
      "4. **Lean Proteins**: Skinless poultry, fish (especially fatty fish like salmon rich in omega-3 fatty acids), and legumes (beans, lentils) provide protein without high saturated fat.\n",
      "5. **Nuts and Seeds**: Almonds, flaxseeds, and chia seeds are good sources of healthy fats and fiber.\n",
      "6. **Low-Fat Dairy**: Low-fat or fat-free yogurt and milk can provide calcium and protein without high saturated fat.\n",
      "\n",
      "### Conclusion:\n",
      "While \"Cheese, cheddar or colby, low-sodium\" can be included in moderation due to its low sodium content, it is essential to balance it with other foods that are lower in saturated fat and higher in fiber. The focus should be on a variety of vegetables, fruits, whole grains, lean proteins, and healthy fats to create a balanced and nutritious diet suitable for managing diabetes and hypertension.\n",
      "Source Document: name = Cheese, cheddar or colby, low-sodium, serving_size = 100 g, calories = 398, total_fat = 33g, saturated_fat = 21g, cholesterol = 100mg, sodium = 21.00 mg, choline = 15.4 mg, folate = 18.00 mcg, folic_acid = 0.00 mcg, niacin = 0.086 mg, pantothenic_acid = 0.311 mg, riboflavin = 0.375 mg, thiamin = 0.021 mg, vitamin_a = 996.00 IU, vitamin_a_rae = 264.00 mcg, carotene_alpha = 0.00 mcg, carotene_beta = 84.00 mcg, cryptoxanthin_beta = 0.00 mcg, lutein_zeaxanthin = 0.00 mcg, lucopene = 0, vitamin_b12 = 0.83 mcg, vitamin_b6 = 0.076 mg, vitamin_c = 0.0 mg, vitamin_d = 24.00 IU, vitamin_e = 0.28 mg, tocopherol_alpha = 0.28 mg, vitamin_k = 2.7 mcg, calcium = 703.00 mg, copper = 0.036 mg, irom = 0.72 mg, magnesium = 27.00 mg, manganese = 0.011 mg, phosphorous = 484.00 mg, potassium = 112.00 mg, selenium = 14.5 mcg, zink = 3.09 mg, protein = 24.35 g, alanine = 0.633 g, arginine = 0.847 g, aspartic_acid = 1.439 g, cystine = 0.111 g, glutamic_acid = 5.480 g, glycine = 0.385 g, histidine = 0.786 g, hydroxyproline = 0, isoleucine = 1.389 g, leucine = 2.145 g, lysine = 1.866 g, methionine = 0.588 g, phenylalanine = 1.179 g, proline = 2.526 g, serine = 1.309 g, threonine = 0.798 g, tryptophan = 0.286 g, tyrosine = 1.080 g, valine = 1.496 g, carbohydrate = 1.91 g, fiber = 0.0 g, sugars = 0.49 g, fructose = 0, galactose = 0, glucose = 0, lactose = 0, maltose = 0, sucrose = 0, fat = 32.62 g, saturated_fatty_acids = 20.768 g, monounsaturated_fatty_acids = 9.189 g, polyunsaturated_fatty_acids = 0.972 g, fatty_acids_total_trans = 100.00 mg, alcohol = 0.0 g, ash = 2.13 g, caffeine = 0.00 mg, theobromine = 0.00 mg, water = 38.98 g\n",
      "Document ID: Unknown\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "Based on the query from my LLM, I want to find all the relevant food names that could be included in the diet.\n",
    "\n",
    "For example, if: \n",
    "query: Dietary plan for people with diabetes and high blood pressure -->\n",
    "output: the food which could be included in the diet based on the nutritional values from the vectorDB suitable for a diet of a patient with diabtes and high BP.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Please list the relevant foods based on the above Question:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# Set up the RetrievalQA chain\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=True\n",
    ")\n",
    "# Function to get the response for a query\n",
    "def get_response(query):\n",
    "    # Retrieve context from the retriever\n",
    "    context = retriever.get_relevant_documents(query)\n",
    "\n",
    "    # If no relevant documents are found, return a default message\n",
    "    if not context:\n",
    "        return {\"answer\": \"No relevant context found.\", \"source_document\": \"None\", \"doc\": \"Unknown\"}\n",
    "\n",
    "    # Prepare the input for the LLM using the expected key 'query'\n",
    "    response = qa_chain({\"query\": query})\n",
    "\n",
    "    # Extract the source document information if available\n",
    "    if response['source_documents']:\n",
    "        source_document = response['source_documents'][0].page_content\n",
    "        doc = response['source_documents'][0].metadata.get('source', 'Unknown')\n",
    "    else:\n",
    "        source_document = \"No source document found.\"\n",
    "        doc = \"Unknown\"\n",
    "\n",
    "    # Extract the answer\n",
    "    answer = response['result']\n",
    "    return {\"answer\": answer, \"source_document\": source_document, \"doc\": doc}\n",
    "\n",
    "# Example usage\n",
    "query = \"Patient has diabetes and hypertension. What are some dietary considerations for these conditions?\"\n",
    "response = get_response(query)\n",
    "print(\"Answer:\", response['answer'])\n",
    "print(\"Source Document:\", response['source_document'])\n",
    "print(\"Document ID:\", response['doc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsroom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
